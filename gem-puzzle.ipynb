{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: solve efficiently a generic $2^n-1$ puzzle using path-search algorithms. <br>\n",
    "Quality: number of actions in the solution. <br>\n",
    "Cost: total number of actions evaluated. <br>\n",
    "Efficiency: Quality vs Cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>A*</h1>\n",
    "In this implementation of A* algorithm, I consider two possible admissable heuristic estimates: <br>\n",
    "1. Manhattan distance. It considers the manhattan distance of each tile (except for 0 encoding a free space) from its current position to its position in the goal state and sums these distances up. <br>\n",
    "2. Enhanced Manhattan. It is based on the previous idea, but adds a penalising factor for tiles which are in the correct row/column but in the wrong order. It's slightly more computationally expensive, but in general it allows to find the path to the goal sooner, with algorithm evaluating less states compared to A* with Manhattan distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import namedtuple, defaultdict\n",
    "from heapq import heappush, heappop\n",
    "from typing import Optional, List, Tuple \n",
    "from dataclasses import dataclass\n",
    "from random import choice\n",
    "from tqdm import tqdm\n",
    "\n",
    "Action = namedtuple('Action', ['pos1', 'pos2'])\n",
    "\n",
    "@dataclass\n",
    "class Node:\n",
    "    state: np.ndarray\n",
    "    parent: Optional['Node']\n",
    "    action: Optional[Action]\n",
    "    g_cost: int  # actual cost from start to this node\n",
    "    h_cost: int  # heuristic estimate to reach the goal state\n",
    "    \n",
    "    def f_cost(self) -> int:\n",
    "        return self.g_cost + self.h_cost\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.f_cost() < other.f_cost()\n",
    "\n",
    "def available_actions(state: np.ndarray) -> list['Action']:\n",
    "    x, y = [int(_[0]) for _ in np.where(state == 0)]\n",
    "    puzzle_dim = state.shape[0]\n",
    "    actions = list()\n",
    "    if x > 0:\n",
    "        actions.append(Action((x, y), (x - 1, y)))\n",
    "    if x < puzzle_dim - 1:\n",
    "        actions.append(Action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(Action((x, y), (x, y - 1)))\n",
    "    if y < puzzle_dim - 1:\n",
    "        actions.append(Action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "def do_action(state: np.ndarray, action: Action) -> np.ndarray:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state\n",
    "\n",
    "def init_puzzle(puzzle_dim: int) -> np.ndarray:\n",
    "    RANDOMIZE_STEPS = 100_000\n",
    "    state = np.array([i for i in range(1, puzzle_dim**2)] + [0]).reshape((puzzle_dim, puzzle_dim))\n",
    "    for r in tqdm(range(RANDOMIZE_STEPS), desc='Randomizing'):\n",
    "        state = do_action(state, choice(available_actions(state)))\n",
    "    return state\n",
    "\n",
    "def manhattan_distance(state: np.ndarray, goal_state: np.ndarray) -> int:\n",
    "    # possible heuristic, sums manhattan distances of all tiles from their current position to their position in the goal state,\n",
    "    # except for 0 (blank tile)\n",
    "    total_distance = 0\n",
    "    puzzle_dim = state.shape[0]\n",
    "    \n",
    "    for i in range(puzzle_dim):\n",
    "        for j in range(puzzle_dim):\n",
    "            if state[i, j] != 0:\n",
    "                # position in the goal state of the current number\n",
    "                goal_pos = np.where(goal_state == state[i, j])\n",
    "                goal_x, goal_y = goal_pos[0][0], goal_pos[1][0]\n",
    "                total_distance += abs(i - goal_x) + abs(j - goal_y)\n",
    "                \n",
    "    return total_distance\n",
    "\n",
    "def enhanced_manhattan(state: np.ndarray, goal_state: np.ndarray) -> int:\n",
    "    # possible heuristic based on manhattan distance with additional penalty for conflicts within a row or a column\n",
    "    def count_conflicts(line1: np.ndarray, line2: np.ndarray) -> int:\n",
    "        #counts conflicts (correct elements but in a wrong order) within a line (row or column)\n",
    "        conflicts = 0\n",
    "        for i in range(len(line1)):\n",
    "            if line1[i] == 0: #skipping blank tile\n",
    "                continue\n",
    "            for j in range(i + 1, len(line1)):\n",
    "                if line1[j] == 0: #skipping blank tile\n",
    "                    continue\n",
    "                # check if tiles are in this line also in the goal state\n",
    "                if (line1[i] in line2) and (line1[j] in line2):\n",
    "                    # get their target positions\n",
    "                    pos_i = np.where(line2 == line1[i])[0][0]\n",
    "                    pos_j = np.where(line2 == line1[j])[0][0]\n",
    "                    # if they're in reverse order, count as conflict (penalised by 2 since each tile must move at least once)\n",
    "                    if pos_i > pos_j:\n",
    "                        conflicts += 2 \n",
    "        return conflicts\n",
    "\n",
    "    #intialising with Manhattan distance cost\n",
    "    cost = manhattan_distance(state, goal_state)\n",
    "    \n",
    "    #conflicts in rows\n",
    "    for i in range(state.shape[0]):\n",
    "        cost += count_conflicts(state[i], goal_state[i])\n",
    "    #conflicts in columns\n",
    "    for j in range(state.shape[1]):\n",
    "        cost += count_conflicts(state[:, j], goal_state[:, j])\n",
    "\n",
    "    return cost\n",
    "\n",
    "class GemPuzzleSolver:\n",
    "    def __init__(self, initial_state: np.ndarray, goal_state: np.ndarray, \n",
    "                 heuristic_func: callable):\n",
    "        self.initial_state = initial_state\n",
    "        self.goal_state = goal_state\n",
    "        self.puzzle_dim = initial_state.shape[0]\n",
    "        self.heuristic_func = heuristic_func\n",
    "        self.states_evaluated = 0\n",
    "        \n",
    "    def state_to_tuple(self, state: np.ndarray) -> tuple:\n",
    "        #utilisied for hashin\n",
    "        return tuple(state.flatten())\n",
    "    \n",
    "    def reconstruct_path(self, node: Node) -> List[Tuple[np.ndarray, Action]]:\n",
    "        # Get the solution path if the goal state is reached\n",
    "        path = []\n",
    "        current = node\n",
    "        while current.parent is not None:\n",
    "            path.append((current.state, current.action))\n",
    "            current = current.parent\n",
    "        path.append((current.state, None))  # initial state added\n",
    "        return path[::-1]  # reverse to get path 'start -> goal'\n",
    "    \n",
    "    def solve(self) -> Tuple[Optional[List[Tuple[np.ndarray, Action]]], int, int]:\n",
    "        # Solving the puzzle with A* algorithm\n",
    "        self.states_evaluated = 0\n",
    "        \n",
    "        # Initialize the start node\n",
    "        start_node = Node(\n",
    "            state=self.initial_state,\n",
    "            parent=None,\n",
    "            action=None,\n",
    "            g_cost=0,\n",
    "            h_cost=self.heuristic_func(self.initial_state, self.goal_state)\n",
    "        )\n",
    "        \n",
    "        # Priority queue for open nodes\n",
    "        open_set = [start_node]\n",
    "        # Dictionary to track the best known g_cost for each state\n",
    "        g_scores = defaultdict(lambda: float('inf'))\n",
    "        g_scores[self.state_to_tuple(self.initial_state)] = 0\n",
    "        # Set of closed (evaluated) nodes\n",
    "        closed_set = set()\n",
    "        \n",
    "        while open_set:\n",
    "            current = heappop(open_set)\n",
    "            current_tuple = self.state_to_tuple(current.state)\n",
    "            \n",
    "            # skip if we've found a better path to this state\n",
    "            if current_tuple in closed_set:\n",
    "                continue\n",
    "            self.states_evaluated += 1\n",
    "            \n",
    "            # do the goal check\n",
    "            if (current.state == self.goal_state).all():\n",
    "                path = self.reconstruct_path(current)\n",
    "                return path, len(path) - 1, self.states_evaluated\n",
    "\n",
    "            closed_set.add(current_tuple)\n",
    "            \n",
    "            # Generate and evaluate all possible moves\n",
    "            for action in available_actions(current.state):\n",
    "                new_state = do_action(current.state, action)\n",
    "                new_state_tuple = self.state_to_tuple(new_state)\n",
    "                \n",
    "                # Skip if we've already evaluated this state\n",
    "                if new_state_tuple in closed_set:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate new g_cost\n",
    "                new_g_cost = current.g_cost + 1\n",
    "                \n",
    "                # Skip if we've found a better path to this state\n",
    "                if new_g_cost >= g_scores[new_state_tuple]:\n",
    "                    continue\n",
    "                \n",
    "                # Create new node\n",
    "                new_node = Node(\n",
    "                    state=new_state,\n",
    "                    parent=current,\n",
    "                    action=action,\n",
    "                    g_cost=new_g_cost,\n",
    "                    h_cost=self.heuristic_func(new_state, self.goal_state)\n",
    "                )\n",
    "                \n",
    "                g_scores[new_state_tuple] = new_g_cost\n",
    "                heappush(open_set, new_node)\n",
    "        \n",
    "        # No solution found\n",
    "        return None, 0, self.states_evaluated\n",
    "\n",
    "def print_solution(path: List[Tuple[np.ndarray, Action]]):\n",
    "    if not path:\n",
    "        print(\"No solution found\")\n",
    "        return\n",
    "        \n",
    "    print(f\"\\nSolution found. {len(path) - 1} moves required.\")\n",
    "    print(\"\\nInitial state:\")\n",
    "    print(path[0][0])\n",
    "    \n",
    "    for i, (state, action) in enumerate(path[1:], 1):\n",
    "        print(f\"\\nMove {i}:\")\n",
    "        if action:\n",
    "            print(f\"Move element from {action.pos2} to {action.pos1}\")\n",
    "        print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Randomizing:   0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Randomizing: 100%|██████████| 100000/100000 [00:02<00:00, 46545.50it/s]\n"
     ]
    }
   ],
   "source": [
    "puzzle_dim = 3\n",
    "initial_state = init_puzzle(puzzle_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solution found. 24 moves required.\n",
      "\n",
      "Initial state:\n",
      "[[3 7 4]\n",
      " [5 0 6]\n",
      " [8 2 1]]\n",
      "\n",
      "Move 1:\n",
      "Move element from (2, 1) to (1, 1)\n",
      "[[3 7 4]\n",
      " [5 2 6]\n",
      " [8 0 1]]\n",
      "\n",
      "Move 2:\n",
      "Move element from (2, 2) to (2, 1)\n",
      "[[3 7 4]\n",
      " [5 2 6]\n",
      " [8 1 0]]\n",
      "\n",
      "Move 3:\n",
      "Move element from (1, 2) to (2, 2)\n",
      "[[3 7 4]\n",
      " [5 2 0]\n",
      " [8 1 6]]\n",
      "\n",
      "Move 4:\n",
      "Move element from (1, 1) to (1, 2)\n",
      "[[3 7 4]\n",
      " [5 0 2]\n",
      " [8 1 6]]\n",
      "\n",
      "Move 5:\n",
      "Move element from (2, 1) to (1, 1)\n",
      "[[3 7 4]\n",
      " [5 1 2]\n",
      " [8 0 6]]\n",
      "\n",
      "Move 6:\n",
      "Move element from (2, 0) to (2, 1)\n",
      "[[3 7 4]\n",
      " [5 1 2]\n",
      " [0 8 6]]\n",
      "\n",
      "Move 7:\n",
      "Move element from (1, 0) to (2, 0)\n",
      "[[3 7 4]\n",
      " [0 1 2]\n",
      " [5 8 6]]\n",
      "\n",
      "Move 8:\n",
      "Move element from (1, 1) to (1, 0)\n",
      "[[3 7 4]\n",
      " [1 0 2]\n",
      " [5 8 6]]\n",
      "\n",
      "Move 9:\n",
      "Move element from (0, 1) to (1, 1)\n",
      "[[3 0 4]\n",
      " [1 7 2]\n",
      " [5 8 6]]\n",
      "\n",
      "Move 10:\n",
      "Move element from (0, 0) to (0, 1)\n",
      "[[0 3 4]\n",
      " [1 7 2]\n",
      " [5 8 6]]\n",
      "\n",
      "Move 11:\n",
      "Move element from (1, 0) to (0, 0)\n",
      "[[1 3 4]\n",
      " [0 7 2]\n",
      " [5 8 6]]\n",
      "\n",
      "Move 12:\n",
      "Move element from (1, 1) to (1, 0)\n",
      "[[1 3 4]\n",
      " [7 0 2]\n",
      " [5 8 6]]\n",
      "\n",
      "Move 13:\n",
      "Move element from (1, 2) to (1, 1)\n",
      "[[1 3 4]\n",
      " [7 2 0]\n",
      " [5 8 6]]\n",
      "\n",
      "Move 14:\n",
      "Move element from (0, 2) to (1, 2)\n",
      "[[1 3 0]\n",
      " [7 2 4]\n",
      " [5 8 6]]\n",
      "\n",
      "Move 15:\n",
      "Move element from (0, 1) to (0, 2)\n",
      "[[1 0 3]\n",
      " [7 2 4]\n",
      " [5 8 6]]\n",
      "\n",
      "Move 16:\n",
      "Move element from (1, 1) to (0, 1)\n",
      "[[1 2 3]\n",
      " [7 0 4]\n",
      " [5 8 6]]\n",
      "\n",
      "Move 17:\n",
      "Move element from (1, 2) to (1, 1)\n",
      "[[1 2 3]\n",
      " [7 4 0]\n",
      " [5 8 6]]\n",
      "\n",
      "Move 18:\n",
      "Move element from (2, 2) to (1, 2)\n",
      "[[1 2 3]\n",
      " [7 4 6]\n",
      " [5 8 0]]\n",
      "\n",
      "Move 19:\n",
      "Move element from (2, 1) to (2, 2)\n",
      "[[1 2 3]\n",
      " [7 4 6]\n",
      " [5 0 8]]\n",
      "\n",
      "Move 20:\n",
      "Move element from (2, 0) to (2, 1)\n",
      "[[1 2 3]\n",
      " [7 4 6]\n",
      " [0 5 8]]\n",
      "\n",
      "Move 21:\n",
      "Move element from (1, 0) to (2, 0)\n",
      "[[1 2 3]\n",
      " [0 4 6]\n",
      " [7 5 8]]\n",
      "\n",
      "Move 22:\n",
      "Move element from (1, 1) to (1, 0)\n",
      "[[1 2 3]\n",
      " [4 0 6]\n",
      " [7 5 8]]\n",
      "\n",
      "Move 23:\n",
      "Move element from (2, 1) to (1, 1)\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 0 8]]\n",
      "\n",
      "Move 24:\n",
      "Move element from (2, 2) to (2, 1)\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 0]]\n",
      "Number of states evaluated: 474\n"
     ]
    }
   ],
   "source": [
    "goal_state = np.array([i for i in range(1, puzzle_dim**2)] + [0]).reshape((puzzle_dim, puzzle_dim))\n",
    "    \n",
    "solver = GemPuzzleSolver(\n",
    "    initial_state=initial_state,\n",
    "    goal_state=goal_state,\n",
    "    heuristic_func=enhanced_manhattan\n",
    ")\n",
    "\n",
    "solution_path, moves, states_evaluated = solver.solve()\n",
    "print_solution(solution_path)\n",
    "print(f\"Number of states evaluated: {states_evaluated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solution found. 24 moves required.\n",
      "\n",
      "Initial state:\n",
      "[[3 7 4]\n",
      " [5 0 6]\n",
      " [8 2 1]]\n",
      "\n",
      "Move 1:\n",
      "Move element from (0, 1) to (1, 1)\n",
      "[[3 0 4]\n",
      " [5 7 6]\n",
      " [8 2 1]]\n",
      "\n",
      "Move 2:\n",
      "Move element from (0, 2) to (0, 1)\n",
      "[[3 4 0]\n",
      " [5 7 6]\n",
      " [8 2 1]]\n",
      "\n",
      "Move 3:\n",
      "Move element from (1, 2) to (0, 2)\n",
      "[[3 4 6]\n",
      " [5 7 0]\n",
      " [8 2 1]]\n",
      "\n",
      "Move 4:\n",
      "Move element from (2, 2) to (1, 2)\n",
      "[[3 4 6]\n",
      " [5 7 1]\n",
      " [8 2 0]]\n",
      "\n",
      "Move 5:\n",
      "Move element from (2, 1) to (2, 2)\n",
      "[[3 4 6]\n",
      " [5 7 1]\n",
      " [8 0 2]]\n",
      "\n",
      "Move 6:\n",
      "Move element from (2, 0) to (2, 1)\n",
      "[[3 4 6]\n",
      " [5 7 1]\n",
      " [0 8 2]]\n",
      "\n",
      "Move 7:\n",
      "Move element from (1, 0) to (2, 0)\n",
      "[[3 4 6]\n",
      " [0 7 1]\n",
      " [5 8 2]]\n",
      "\n",
      "Move 8:\n",
      "Move element from (1, 1) to (1, 0)\n",
      "[[3 4 6]\n",
      " [7 0 1]\n",
      " [5 8 2]]\n",
      "\n",
      "Move 9:\n",
      "Move element from (1, 2) to (1, 1)\n",
      "[[3 4 6]\n",
      " [7 1 0]\n",
      " [5 8 2]]\n",
      "\n",
      "Move 10:\n",
      "Move element from (2, 2) to (1, 2)\n",
      "[[3 4 6]\n",
      " [7 1 2]\n",
      " [5 8 0]]\n",
      "\n",
      "Move 11:\n",
      "Move element from (2, 1) to (2, 2)\n",
      "[[3 4 6]\n",
      " [7 1 2]\n",
      " [5 0 8]]\n",
      "\n",
      "Move 12:\n",
      "Move element from (2, 0) to (2, 1)\n",
      "[[3 4 6]\n",
      " [7 1 2]\n",
      " [0 5 8]]\n",
      "\n",
      "Move 13:\n",
      "Move element from (1, 0) to (2, 0)\n",
      "[[3 4 6]\n",
      " [0 1 2]\n",
      " [7 5 8]]\n",
      "\n",
      "Move 14:\n",
      "Move element from (1, 1) to (1, 0)\n",
      "[[3 4 6]\n",
      " [1 0 2]\n",
      " [7 5 8]]\n",
      "\n",
      "Move 15:\n",
      "Move element from (0, 1) to (1, 1)\n",
      "[[3 0 6]\n",
      " [1 4 2]\n",
      " [7 5 8]]\n",
      "\n",
      "Move 16:\n",
      "Move element from (0, 0) to (0, 1)\n",
      "[[0 3 6]\n",
      " [1 4 2]\n",
      " [7 5 8]]\n",
      "\n",
      "Move 17:\n",
      "Move element from (1, 0) to (0, 0)\n",
      "[[1 3 6]\n",
      " [0 4 2]\n",
      " [7 5 8]]\n",
      "\n",
      "Move 18:\n",
      "Move element from (1, 1) to (1, 0)\n",
      "[[1 3 6]\n",
      " [4 0 2]\n",
      " [7 5 8]]\n",
      "\n",
      "Move 19:\n",
      "Move element from (1, 2) to (1, 1)\n",
      "[[1 3 6]\n",
      " [4 2 0]\n",
      " [7 5 8]]\n",
      "\n",
      "Move 20:\n",
      "Move element from (0, 2) to (1, 2)\n",
      "[[1 3 0]\n",
      " [4 2 6]\n",
      " [7 5 8]]\n",
      "\n",
      "Move 21:\n",
      "Move element from (0, 1) to (0, 2)\n",
      "[[1 0 3]\n",
      " [4 2 6]\n",
      " [7 5 8]]\n",
      "\n",
      "Move 22:\n",
      "Move element from (1, 1) to (0, 1)\n",
      "[[1 2 3]\n",
      " [4 0 6]\n",
      " [7 5 8]]\n",
      "\n",
      "Move 23:\n",
      "Move element from (2, 1) to (1, 1)\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 0 8]]\n",
      "\n",
      "Move 24:\n",
      "Move element from (2, 2) to (2, 1)\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 0]]\n",
      "Number of states evaluated: 1063\n"
     ]
    }
   ],
   "source": [
    "solver = GemPuzzleSolver(\n",
    "    initial_state=initial_state,\n",
    "    goal_state=goal_state,\n",
    "    heuristic_func=manhattan_distance\n",
    ")\n",
    "\n",
    "solution_path, moves, states_evaluated = solver.solve()\n",
    "print_solution(solution_path)\n",
    "print(f\"Number of states evaluated: {states_evaluated}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
